{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "from math import exp\n",
    "from tqdm import tqdm\n",
    "\n",
    "from kornia.filters.sobel import Sobel\n",
    "from torchmetrics import StructuralSimilarityIndexMeasure as SSIM\n",
    "from dataset import DEMDataset\n",
    "from model import *\n",
    "from utils import calculatePSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Training on device:\", device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(DEMDataset(load_dir = '/kaggle/input/demdataset8020/train/', \n",
    "                                  transform = transforms.Compose([transforms.ToTensor()]))\n",
    "                            ,batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(DEMDataset(load_dir = '/kaggle/input/demdataset8020/test/',\n",
    "                                transform = transforms.Compose([transforms.ToTensor()]))\n",
    "                                ,batch_size=8, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualising the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hr, lr in train_loader:\n",
    "    sobel = Sobel()\n",
    "    edges = sobel(hr)\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(36, 12))\n",
    "    axes[0].set_yticklabels([])\n",
    "    axes[0].imshow(hr[0].squeeze(), cmap='gray')\n",
    "    axes[1].imshow(lr[0].squeeze(), cmap='gray')\n",
    "    axes[2].imshow(edges[0].squeeze(), cmap='gray')\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### declaring models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = MobileSR()\n",
    "generator = generator.to(device)\n",
    "discriminator = Discriminator(1, 128)\n",
    "discriminator = discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gradientAwareLoss(nn.Module): \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sobelFilter = Sobel().to('cuda')\n",
    "        self.l1Loss = nn.L1Loss().to('cuda')\n",
    "\n",
    "    def forward(self, hr, sr):\n",
    "        hrEdgeMap = self.sobelFilter(hr)\n",
    "        srEdgeMap = self.sobelFilter(sr)\n",
    "        return self.l1Loss(hrEdgeMap, srEdgeMap) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1Loss = nn.L1Loss().to(device) \n",
    "edgeLoss = gradientAwareLoss().to(device) \n",
    "ssim = SSIM().to(device) \n",
    "anotherl1Loss = nn.L1Loss().to(device) \n",
    "\n",
    "optim_G = torch.optim.Adam(generator.parameters(), lr=0.00001)\n",
    "optim_D = torch.optim.Adam(discriminator.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from torchvision.utils import make_grid\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"SRTGAN-Bic\", name=\"exp2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "num_train_batches = float(len(train_loader))\n",
    "num_val_batches = float(len(test_loader))\n",
    "\n",
    "def train_one_epoch(epoch):\n",
    "    print(f\"Epoch {epoch}: \", end =\"\")\n",
    "    \n",
    "    l1_loss_per_epoch = 0.0\n",
    "    edge_loss_per_epoch = 0.0\n",
    "    ssim_loss_per_epoch = 0.0\n",
    "    ssim_per_epoch = 0.0\n",
    "    psnr_per_epoch = 0.0\n",
    "    total_loss_per_epoch = 0.0\n",
    "    D_adv_loss = 0\n",
    "    \n",
    "    generator.train()\n",
    "    for batch, (hr, lr) in enumerate(tqdm(train_loader)):\n",
    "\n",
    "        for p in discriminator.parameters():\n",
    "            p.requires_grad = False\n",
    "        #training generator\n",
    "        optim_G.zero_grad()\n",
    " \n",
    "        lr_images = lr.to(device)\n",
    "        hr_images = hr.to(device)\n",
    "        lr_images = lr_images.float()\n",
    "        predicted_hr_images = generator(lr_images)\n",
    "        predicted_hr_labels = discriminator(predicted_hr_images)\n",
    "        gf_loss = F.binary_cross_entropy_with_logits(predicted_hr_labels, torch.ones_like(predicted_hr_labels)) #adverserial loss\n",
    "      \n",
    "      \n",
    "        # reconstruction loss    \n",
    "      \n",
    "        l1_loss_per_sample = l1Loss(hr_images*1000, predicted_hr_images*1000)\n",
    "        ssim_per_sample = ssim(hr_images, predicted_hr_images)\n",
    "        ssim_loss_per_sample = 1 - ssim_per_sample\n",
    "        edge_loss = edgeLoss(hr_images*1000, predicted_hr_images*1000)  \n",
    "        reconstruction_loss = l1_loss_per_sample + 100*(ssim_loss_per_sample) + 50*edge_loss\n",
    "        t_loss = reconstruction_loss + 50*gf_loss\n",
    "        \n",
    "      \n",
    "        t_loss.backward()\n",
    "        optim_G.step()\n",
    "      \n",
    "        psnr_per_sample = calculatePSNR(hr_images.detach().cpu().numpy(), predicted_hr_images.detach().cpu().numpy())\n",
    "    \n",
    "        l1_loss_per_epoch += l1_loss_per_sample.item()\n",
    "        edge_loss_per_epoch += edge_loss.item() \n",
    "        ssim_loss_per_epoch += ssim_loss_per_sample.item() \n",
    "        ssim_per_epoch += ssim_per_sample.item()\n",
    "        psnr_per_epoch += psnr_per_sample \n",
    "        total_loss_per_epoch += t_loss.item()\n",
    "      \n",
    "        # training discriminator\n",
    "        for p in discriminator.parameters():\n",
    "            p.requires_grad = True\n",
    "        optim_D.zero_grad()\n",
    "        predicted_hr_images = generator(lr_images).detach() # avoid back propogation to generator\n",
    "        hr_images = hr_images.float()\n",
    "        adv_hr_real = discriminator(hr_images)\n",
    "        adv_hr_fake = discriminator(predicted_hr_images)\n",
    "        df_loss = F.binary_cross_entropy_with_logits(adv_hr_real, torch.ones_like(adv_hr_real)) + F.binary_cross_entropy_with_logits(adv_hr_fake, torch.zeros_like(adv_hr_fake))\n",
    "        D_adv_loss += df_loss.item()\n",
    "        df_loss.backward()\n",
    "        optim_D.step()\n",
    "    \n",
    "    l1_loss_per_epoch /= float(len(train_loader))\n",
    "    edge_loss_per_epoch /= float(len(train_loader))\n",
    "    ssim_loss_per_epoch /= float(len(train_loader))\n",
    "    ssim_per_epoch /= float(len(train_loader))\n",
    "    psnr_per_epoch /= float(len(train_loader))\n",
    "    total_loss_per_epoch /= float(len(train_loader))\n",
    "    \n",
    "    wandb.log({\"Train L1 Loss\": l1_loss_per_epoch})\n",
    "    wandb.log({\"Train Edge Loss\": edge_loss_per_epoch})\n",
    "    wandb.log({\"Train SSIM Loss\": ssim_loss_per_epoch})\n",
    "    wandb.log({\"Train Total Loss\": total_loss_per_epoch})\n",
    "    wandb.log({\"Train SSIM\": ssim_per_epoch})\n",
    "    wandb.log({\"Train PSNR\": psnr_per_epoch})\n",
    "    \n",
    "    print(f\"(Train) L1 Loss: {l1_loss_per_epoch:.3f} | SSIM Loss: {ssim_loss_per_epoch:.3f} | Edge Loss: {edge_loss_per_epoch:.3f} | Total Loss: {total_loss_per_epoch:.3f}\")\n",
    "    print(f\"SSIM: {ssim_per_epoch:.3f} | PSNR: {psnr_per_epoch}\")\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    return psnr_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_one_epoch(epoch):\n",
    "    ssim_per_epoch = 0.0\n",
    "    psnr_per_epoch = 0.0\n",
    "    b_ssim_per_epoch = 0.0\n",
    "    b_psnr_per_epoch = 0.0\n",
    "    \n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        for hr, lr in tqdm(test_loader):\n",
    "            batched_hr, batched_lr = hr.to(device), lr.to(device)\n",
    "            predicted_sr = generator(batched_lr)\n",
    "                \n",
    "            bilinear_sr = F.interpolate(batched_lr, scale_factor=2, mode='bilinear')\n",
    "            \n",
    "\n",
    "            ssim_per_epoch += ssim(batched_hr, predicted_sr)\n",
    "            psnr_per_epoch += calculatePSNR(batched_hr.cpu().numpy(), predicted_sr.cpu().numpy())\n",
    "\n",
    "            b_ssim_per_epoch += ssim(batched_hr, bilinear_sr)\n",
    "            b_psnr_per_epoch += calculatePSNR(batched_hr.cpu().numpy(), bilinear_sr.cpu().numpy())\n",
    "\n",
    "            grid1 = make_grid(batched_lr[:4])\n",
    "            grid2 = make_grid(batched_hr[:4])\n",
    "            grid3 = make_grid(predicted_sr[:4])\n",
    "            grid4 = make_grid(bilinear_sr[:4])\n",
    "\n",
    "            grid1 = wandb.Image(grid1, caption=\"Low Resolution DEM\")\n",
    "            grid2 = wandb.Image(grid2, caption=\"High Resolution DEM\")\n",
    "            grid3 = wandb.Image(grid3, caption=\"Reconstructed High Resolution DEM\")\n",
    "            grid4 = wandb.Image(grid4, caption=\"Bilinear High Resolution DEM\")\n",
    "            \n",
    "            wandb.log({\"Original LR\": grid1})\n",
    "            wandb.log({\"Original HR\": grid2})\n",
    "            wandb.log({\"Reconstruced\": grid3})\n",
    "            wandb.log({\"Bilinear\": grid4})\n",
    "\n",
    "        ssim_per_epoch /= float(len(test_loader))\n",
    "        psnr_per_epoch /= float(len(test_loader))\n",
    "        b_ssim_per_epoch /= float(len(test_loader))\n",
    "        b_psnr_per_epoch /= float(len(test_loader))\n",
    "\n",
    "        wandb.log({\"Test Predicted SSIM\": ssim_per_epoch})\n",
    "        wandb.log({\"Test Predicted PSNR\": psnr_per_epoch})\n",
    "        wandb.log({\"Bilinear SSIM\": b_ssim_per_epoch})\n",
    "        wandb.log({\"Bilinear PSNR\": b_psnr_per_epoch})\n",
    "\n",
    "        print(f\"(Val) SSIM: {ssim_per_epoch:.3f} | PSNR: {psnr_per_epoch:.3f}\")\n",
    "        print(f\"(Bil) SSIM: {b_ssim_per_epoch:.3f} | PSNR: {b_psnr_per_epoch:.3f}\")\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return psnr_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_psnr = 0\n",
    "count = 0\n",
    "prev_psnr =0\n",
    "for i in range(100):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    train_psnr = train_one_epoch(i)\n",
    "    valid_psnr = valid_one_epoch(i)\n",
    "    \n",
    "    if valid_psnr >= prev_psnr:\n",
    "        count =0\n",
    "    else :\n",
    "        count +=1\n",
    "        if count ==5 :\n",
    "            generator = generator.load_state_dict(torch.load(f\"best_model_{best_psnr}.pt\"))\n",
    "    \n",
    "    if valid_psnr > best_psnr:\n",
    "        best_psnr = valid_psnr\n",
    "        torch.save(generator.state_dict(), f\"best_model_{best_psnr}.pt\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
